{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e59935a5-e05d-4992-a771-ea50c5985135",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "---\n",
    "Author: Mustapha Bouhsen <br>\n",
    "Email : mustapha.bouhsen@habitat-nature.com <br>\n",
    "[LinkedIn](https://www.linkedin.com/in/mustapha-bouhsen/)<br>\n",
    "Date: July 15, 2024<br>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6740493-7b22-4694-8f30-c605084c8a4e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3657b37-d656-4100-8808-0b5356a2e26e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create the mount folder\n",
    "\n",
    "In this section, we create a mount folder to get access the data in the blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d855367b-723c-4a93-95b6-31593a1d9170",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# storage_account_name = \"datatest42\"\n",
    "# storage_key = \"sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupyx&se=2024-08-31T03:31:55Z&st=2024-07-15T19:31:55Z&spr=https&sig=L3Ly%2Fos9foips1W5CkGiyg0hXZc%2BT2FzPN%2FuHOe%2BY58%3D\"\n",
    "# container_name = \"database\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f7a6330-3b8a-45c5-95f7-aa04c85cbfd3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# mount_point = \"/mnt/database\"\n",
    "\n",
    "# dbutils.fs.mount(\n",
    "#   source = f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/\",\n",
    "#   mount_point = mount_point,\n",
    "#   extra_configs = {f\"fs.azure.sas.{container_name}.{storage_account_name}.blob.core.windows.net\":storage_key})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2eceb6a-7aac-4a46-80eb-ab3cec19b4d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Recursive File Path Retrieval in Nested Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "875245b4-c0f8-4982-a4d8-631bbcb61408",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_files_paths_from_folders(folder_path, endsWith=None):\n",
    "    \"\"\"\n",
    "    Recursively retrieves the paths of all files within the specified folder and its subfolders.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): The path to the folder for which file paths are to be retrieved.\n",
    "    - endsWith (list[str], optional): The suffix to filter files by.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list containing the paths of all files within the specified folder and its subfolders that end with the specified suffix.\n",
    "    \"\"\"\n",
    "    # Get the list of paths (files and subfolders) within the specified folder\n",
    "    paths = dbutils.fs.ls(folder_path)\n",
    "\n",
    "    # Initialize an empty list to store file paths\n",
    "    my_paths = []\n",
    "\n",
    "    # Iterate through the paths to identify files and subfolders\n",
    "    for key in paths:\n",
    "        # Check if the current path corresponds to a file\n",
    "        if key.isFile():\n",
    "            # If it's a file, append its path to the list\n",
    "            my_paths.append(key[0])\n",
    "        else:\n",
    "            # If it's a subfolder, recursively call the function to get file paths within the subfolder\n",
    "            my_paths = my_paths + get_files_paths_from_folders(key[0])\n",
    "\n",
    "    if endsWith != None:\n",
    "        # Filter the list of paths to include only those ending with the specified suffix\n",
    "        my_paths = [x for x in my_paths if any(ext in x for ext in endsWith)]\n",
    "\n",
    "    # Return the final list of file paths\n",
    "    return my_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e50ed8c-16d4-4c70-8185-f4d12ed42e4d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Function to create file path from the blob storage with the key access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff16d6cb-ae83-4c58-a2e6-1af9b5ea7635",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_file_paths(path, storage_account_name, blob_key=''):\n",
    "    \"\"\"\n",
    "    Constructs a URL for accessing a file in an Azure Blob Storage container.\n",
    "\n",
    "    Parameters:\n",
    "    - path (list of str): A list of strings representing the hierarchical path to the file in the storage container.\n",
    "    - storage_account_name (str): The name of the Azure Storage account.\n",
    "    - blob_key (str, optional): The optional key or token for accessing the blob. Default is an empty string.\n",
    "\n",
    "    Returns:\n",
    "    - str: The complete URL for accessing the file in Azure Blob Storage.\n",
    "    \"\"\"\n",
    "    my_path = \"/\".join(path)\n",
    "    my_path = f\"https://{storage_account_name}.blob.core.windows.net/{my_path}?{blob_key}\"\n",
    "    return my_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a13693f-2580-4972-bbb4-2f0497e59a95",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##  Function to creates a lookup table (DataFrame) from a list of file paths, parsing specific metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "228f91f8-f0a4-4784-be31-38a44c9b51a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def created_lookup_table(files_paths, storage_account_name, blob_key=''):\n",
    "    \"\"\"\n",
    "    Creates a lookup table (DataFrame) from a list of file paths, parsing specific metadata.\n",
    "\n",
    "    Parameters:\n",
    "    - files_paths (list of str): A list of file paths in Azure Blob Storage.\n",
    "    - storage_account_name (str): The name of the Azure Storage account.\n",
    "    - blob_key (str, optional): The optional key or token for accessing the blob. Default is an empty string.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A pandas DataFrame containing parsed metadata columns ('theme', 'country', 'region', 'subject_*', 'year', 'file_path').\n",
    "    \"\"\"\n",
    "\n",
    "    files = [path.split(\"/\")[2:] for path in files_paths]\n",
    "\n",
    "    # Initialize an empty list to hold the parsed data\n",
    "    parsed_data = []\n",
    "\n",
    "    # Iterate over each sublist\n",
    "    for path in files:\n",
    "        # Initialize a dictionary to hold the row data\n",
    "        row_data = {}\n",
    "        # The third element is the theme\n",
    "        row_data[\"theme\"] = path[2] \n",
    "        # Counter for subjects\n",
    "        subject_counter = 1\n",
    "\n",
    "        # Iterate over the remaining elements\n",
    "        for item in path[3:]:\n",
    "            if \"=\" in item:\n",
    "                key, value = item.split(\"=\")\n",
    "                if key == 'subject':\n",
    "                    # Use a counter to create dynamic subject columns\n",
    "                    key = f\"subject_{subject_counter}\"\n",
    "                    subject_counter += 1\n",
    "\n",
    "                row_data[key] = value\n",
    "            \n",
    "            else:\n",
    "                row_data['file_path'] = create_file_paths(path, storage_account_name, blob_key)\n",
    "\n",
    "        # Append the row data to the parsed_data list\n",
    "        parsed_data.append(row_data)\n",
    "    \n",
    "    # Create a DataFrame from the parsed data\n",
    "    df = pd.DataFrame(parsed_data)\n",
    "\n",
    "    # Ensure the subjects are after the region column\n",
    "    subject_columns = [col for col in df.columns if col.startswith('subject_')]\n",
    "    column_order = ['theme', 'country', 'region'] + subject_columns + [\"year\", \"file_path\"]\n",
    "    df = df[column_order]\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "utilities",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
